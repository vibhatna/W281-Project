{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**This notebook contains code to load training dataset and create subsets of data used for feature and model development in the project.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import csv\n",
    "import pathlib\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'landmark_id'], dtype='object')\n",
      "Total Images: 1580470\n"
     ]
    }
   ],
   "source": [
    "# load training data file from https://www.kaggle.com/competitions/landmark-recognition-2021/data?select=train.csv\n",
    "TRAINING_FILE = '../Data/landmark-recognition-2021/train.csv'\n",
    "df_train = pd.read_csv(TRAINING_FILE)\n",
    "\n",
    "# print total number of images\n",
    "print(df_train.columns)\n",
    "print(f'Total Images: {len(df_train.landmark_id.values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count images per class\n",
    "def extract_class_statistics(df_train):\n",
    "    classes = {}\n",
    "    for lid in df_train.landmark_id.values:\n",
    "        if lid not in classes:\n",
    "            classes[lid] = 0\n",
    "        classes[lid] += 1\n",
    "    return classes\n",
    "\n",
    "# find classes with images >= threshold\n",
    "def classes_more_than_threshold(classes, threshold):\n",
    "    reduced_classes = {}\n",
    "    for key, value in classes.items():\n",
    "        if value >= threshold:\n",
    "            reduced_classes[key] = value\n",
    "    return reduced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = extract_class_statistics(df_train)\n",
    "sorted_classes = {k: v for k, v in sorted(classes.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Clases with atleast 500 images: 51\n"
     ]
    }
   ],
   "source": [
    "threshold = 500\n",
    "reduced_classes = classes_more_than_threshold(classes, threshold)\n",
    "sorted_reduced_classes = {k: v for k, v in sorted(reduced_classes.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(f'Total Clases with atleast {threshold} images: {len(reduced_classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with only images from classes with 500 or more images\n",
    "with open('TargetClasses.csv', \"w\", newline='') as filetc:\n",
    "    writertc = csv.writer(filetc, delimiter=',')\n",
    "    writertc.writerow(('landmark_id','Frequency'))\n",
    "    for key,value in reduced_classes.items():\n",
    "        writertc.writerow((key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images (Reduced Data): 45579\n"
     ]
    }
   ],
   "source": [
    "# create subset of images corresponding to relevant landmark classes\n",
    "index = 0\n",
    "target_data = {}\n",
    "for image_id in df_train['id']:\n",
    "    landmark_id = df_train['landmark_id'][index]\n",
    "    index += 1\n",
    "    \n",
    "    if landmark_id in sorted_reduced_classes:\n",
    "        target_data[image_id] = landmark_id\n",
    "\n",
    "with open('TargetData.csv', \"w\", newline='') as filetd:\n",
    "    writertd = csv.writer(filetd, delimiter=',')\n",
    "    writertd.writerow(('id','landmark_id'))\n",
    "    for key,value in target_data.items():\n",
    "        writertd.writerow((key, value))\n",
    "\n",
    "print(f'Total Images (Reduced Data): {len(target_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_dir = 'C:/W281-Project/Data/landmark-recognition-2021/train'\n",
    "image_paths = [x for x in pathlib.Path(image_root_dir).rglob('*.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_root_dir = 'C:/W281-Project/Notebook/TargetImages'\n",
    "for path in image_paths:\n",
    "    image_id = path.name.replace('.jpg', '')\n",
    "    if image_id in target_data:\n",
    "        shutil.copy(path, target_image_root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
