{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df894660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733035a4",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639ff3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH = './TargetData-TF-Train.csv'\n",
    "VALIDATION_DATA_PATH = './TargetData-TF-Valid.csv'\n",
    "VALIDATION_DATA_PREDICTION_PATH = './TargetData-TF-Valid-PredictionORB.csv'\n",
    "TEST_DATA_PATH = './TargetData-TF-Test.csv'\n",
    "\n",
    "IMAGE_FOLDER_PATH = './TargetImages-TF/'\n",
    "\n",
    "TARGET_CLASSES_MAPPING = {}\n",
    "TARGET_CLASSES_MAPPING[10419] = 'Qutub Minar'\n",
    "TARGET_CLASSES_MAPPING[47378] = 'Eiffel Tower'\n",
    "TARGET_CLASSES_MAPPING[168098] = 'Golden Gate Bridge'\n",
    "TARGET_CLASSES_MAPPING[162833] = 'Pakistan Monument'\n",
    "TARGET_CLASSES_MAPPING[1924] = 'Niagara River'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bd01c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad6ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HarrisKeypointDetector(in_image, n=2, w=3, k=0.04, verbose=True):\n",
    "    \n",
    "    harrisImage = cv2.cornerHarris(in_image, n, w, k)\n",
    "    thresh = 0.05 * harrisImage.max()\n",
    "    harrisMaxImage = harrisImage > thresh\n",
    "    \n",
    "    height, width = in_image.shape[:2]\n",
    "    features = []\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            \n",
    "            if not harrisMaxImage[y, x]:\n",
    "                continue\n",
    "\n",
    "            f = cv2.KeyPoint()\n",
    "            f.pt = (x, y)\n",
    "            f.response = harrisImage[y,x]\n",
    "            features.append(f)\n",
    "           \n",
    "    return features\n",
    "\n",
    "def read_image(in_path):\n",
    "\n",
    "    img = plt.imread(in_path)\n",
    "    if np.max(img) > 1:\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        img = img[:, :, 2].copy()\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def ORBFeatureDescriptor(grayImage, keypoints):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp, des = orb.compute((grayImage * 255).astype(np.uint8), keypoints)\n",
    "    return des\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    id_mapping = {}\n",
    "    id_des = {}\n",
    "    \n",
    "    \n",
    "    for index in range(len(df)):\n",
    "        image_id = df['id'][index]\n",
    "        image_label = df['landmark_id'][index]\n",
    "        \n",
    "        if index % 25 == 0:\n",
    "            print(f'Read {index} images')\n",
    "            \n",
    "        id_mapping[image_id] = image_label\n",
    "        image_path = os.path.join(IMAGE_FOLDER_PATH, image_id + '.jpg')\n",
    "        image = read_image(image_path)        \n",
    "        \n",
    "        kp = HarrisKeypointDetector(image, n=2)        \n",
    "        des = ORBFeatureDescriptor(image, kp)\n",
    "        \n",
    "        id_des[image_id] = des\n",
    "        \n",
    "    return id_mapping, id_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269c1f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 images\n",
      "Read 25 images\n",
      "Read 50 images\n",
      "Read 75 images\n",
      "Read 100 images\n",
      "Read 125 images\n",
      "Read 150 images\n",
      "Read 175 images\n",
      "Read 200 images\n",
      "Read 225 images\n"
     ]
    }
   ],
   "source": [
    "train_id_mapping, train_id_des = load_data(TRAINING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29256f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 images\n",
      "Read 25 images\n",
      "Read 50 images\n",
      "Read 75 images\n",
      "Read 100 images\n"
     ]
    }
   ],
   "source": [
    "valid_id_mapping, valid_id_des = load_data(VALIDATION_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b94b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(desc1, desc2):\n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "    \n",
    "    return len(good)\n",
    "\n",
    "def tf_predictor(reference_id_mapping, reference_id_des, sample_des):\n",
    "    \n",
    "    good_matches = {}\n",
    "    for key,values in TARGET_CLASSES_MAPPING.items():\n",
    "        good_matches[key] = 0\n",
    "        \n",
    "    gm_count = 0\n",
    "    max_gm_count = 0\n",
    "    max_gm_label = -1\n",
    "    max_gm_reference = ''\n",
    "    for image_id, image_label in reference_id_mapping.items():\n",
    "        \n",
    "        gm_count = feature_matching(reference_id_des[image_id], sample_des)\n",
    "        \n",
    "        good_matches[image_label] += gm_count\n",
    "        \n",
    "        if gm_count > max_gm_count:\n",
    "            max_gm_count = gm_count\n",
    "            max_gm_label = image_label\n",
    "            max_gm_reference = image_id            \n",
    "        \n",
    "        \n",
    "    max_agg_matches = 0\n",
    "    max_agg_label = -1\n",
    "    for image_label, good_match_count in  good_matches.items():\n",
    "        if good_match_count > max_agg_matches:\n",
    "            max_agg_matches = good_match_count\n",
    "            max_agg_label = image_label            \n",
    "    \n",
    "    return max_agg_label, max_gm_label, max_gm_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d695f04",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6013dbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vibhatna.FAREAST\\AppData\\Local\\Temp\\ipykernel_33908\\1809165047.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['prediction_agg'][index] = max_agg_label\n",
      "C:\\Users\\vibhatna.FAREAST\\AppData\\Local\\Temp\\ipykernel_33908\\1809165047.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['prediction_max'][index] = max_gm_label\n",
      "C:\\Users\\vibhatna.FAREAST\\AppData\\Local\\Temp\\ipykernel_33908\\1809165047.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['prediction_max_ref'][index] = max_gm_reference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 1, Correct Agg Count: 0, Correct Max Count: 0\n",
      "Total Images: 11, Correct Agg Count: 2, Correct Max Count: 3\n",
      "Total Images: 21, Correct Agg Count: 5, Correct Max Count: 5\n",
      "Total Images: 31, Correct Agg Count: 6, Correct Max Count: 7\n",
      "Total Images: 41, Correct Agg Count: 7, Correct Max Count: 10\n",
      "Total Images: 51, Correct Agg Count: 12, Correct Max Count: 16\n",
      "Total Images: 61, Correct Agg Count: 13, Correct Max Count: 18\n",
      "Total Images: 71, Correct Agg Count: 18, Correct Max Count: 23\n",
      "Total Images: 81, Correct Agg Count: 19, Correct Max Count: 24\n",
      "Total Images: 91, Correct Agg Count: 21, Correct Max Count: 26\n",
      "Total Images: 101, Correct Agg Count: 25, Correct Max Count: 30\n",
      "Total Images: 111, Correct Agg Count: 28, Correct Max Count: 32\n",
      "Total Images: 121, Correct Agg Count: 31, Correct Max Count: 36\n"
     ]
    }
   ],
   "source": [
    "df_valid = pd.read_csv(VALIDATION_DATA_PATH)\n",
    "df_valid['prediction_agg'] = 'Missing Prediction'\n",
    "df_valid['prediction_max'] = 'Missing Prediction'\n",
    "df_valid['prediction_max_ref'] = 'Missing Prediction'\n",
    "\n",
    "total_test_correct_agg = 0\n",
    "total_test_correct_max = 0\n",
    "index = 0\n",
    "\n",
    "for index in range(len(df_valid)):\n",
    "    image_id = df_valid['id'][index]\n",
    "    image_label = df_valid['landmark_id'][index]\n",
    "    \n",
    "    max_agg_label, max_gm_label, max_gm_reference= tf_predictor(\n",
    "        train_id_mapping, train_id_des, valid_id_des[image_id])\n",
    "    \n",
    "    \n",
    "    if image_label == max_agg_label:\n",
    "        total_test_correct_agg += 1\n",
    "    \n",
    "    if image_label == max_gm_label:\n",
    "        total_test_correct_max += 1\n",
    "        \n",
    "    \n",
    "    df_valid['prediction_agg'][index] = max_agg_label\n",
    "    df_valid['prediction_max'][index] = max_gm_label\n",
    "    df_valid['prediction_max_ref'][index] = max_gm_reference\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        print(f'Total Images: {index + 1}, Correct Agg Count: {total_test_correct_agg}, Correct Max Count: {total_test_correct_max}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98293832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 125, Correct Agg Count: 32, Correct Max Count: 36\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Images: {index + 1}, Correct Agg Count: {total_test_correct_agg}, Correct Max Count: {total_test_correct_max}')\n",
    "df_valid.to_csv(VALIDATION_DATA_PREDICTION_PATH, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb77bfb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a9df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308cc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2e85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29378f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7396ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2d860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15bb78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "W281",
   "language": "python",
   "name": "w281"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
